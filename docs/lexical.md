# Lexical Analysis

A Python program is read by a parser. Input to the parser is a stream of tokens
generated by a lexical analyzer.  
Lexical analyzer determines the grams text's encoding (UTF-8) by default and
decodes the text into source characters. If text cannot be decoded, a
`SyntaxError` is raised.  

## Line Structure

* Logical Lines
* Physical Lines
* Comments
* Encoding Instructions
* Explicit Line Joining
* Implicit Line Joining
* Blank Lines
* Indentation
* Whitespace between Tokens

## Names

* `A-Z`, `a-z`, `_` and except for the first character, the digits `0` to `9`
* Besides these, names can also use "letter-like" and "number-like" characters
from outside the ASCII range

### Keywords

Reserved words that cannot be used as ordinary identifiers

```
False      await      else       import     pass
None       break      except     in         raise
True       class      finally    is         return
and        continue   for        lambda     try
as         def        from       nonlocal   while
assert     del        global     not        with
async      elif       if         or         yield
```

### Soft Keywords

Some names are only reserved under specific contexts.

* `match`, `case` and `_` when used in the `match` statements
* `type` when used in the `type` statement

As soft keywords, their use in the grammar is possible while still preserving
the compatiblity with existing code that uses these names as identifier names.

### Reserved classes of identifiers

* `_*` Not imported by `from module import *`
* `_` - match statement
* `__*__` dunder names. These names are defined by the interpreter and its
implementation
* `__*` class private names. Names in this category, when used within the
context of a class definition, are re-written to use a mangled form to help
avoid name clashes between "private" attributes of base and derived classes.

## Literals

* `string`
* `bytes`
* `numeric`
* denoted using keywords (`None`, `True`, `False`)
* `wllipsis token` (`...`)

## String and Bytes Literals

### Trupple Quoted Strings
### String Prefixes

* `b`
* `r`
* `f`
* `t`
* `u` No effect (allowed for backwards compatiblity)

Prefixes are case insensitive and can be combined with others

### Bytes Literals

They produce an instance of `bytes` type instead of `str` type. They may only
contain ASCII characters, bytes with a numeric value of 128 or greater must be
expressed with escape sequences

```python
b'\x89PNG\r\n\x1a\n'

list(b'\x89PNG\r\n\x1a\n')
```
Idk what this garbage was.

### Raw String

Treat backslashes as literal characters. Can be used for quotes but the
backslack will still be present in text.

### f string

* doubled curly braces '{{' or '}}' are replaced with the corresponding single
curly brace.
* A single opening curly bracket '{' marks a replacement field, which starts
with a Python expression.
* To display both the expression text and its value after evaluation,
(useful in debugging), an equal sign '=' may be added after the expression.
* A conversion field, introduced by an exclamation point `!` may follow.
* A format specifier may also be appended, introduced by a colon `:`.
* A replacement field ends with a closing curly bracket `}`.

```python
name = "Fred"
f"He said his name is {name!r}."

f"He said his name is {repr(name)}."  # repr() is equivalent to !r

width = 10
precision = 4
value = decimal.Decimal("12.34567")
f"result: {value:{width}.{precision}}"  # nested fields

today = datetime(year=2017, month=1, day=27)
f"{today:%B %d, %Y}"  # using date format specifier

f"{today=:%B %d, %Y}" # using date format specifier and debugging

number = 1024
f"{number:#0x}"  # using integer format specifier

foo = "bar"
f"{ foo = }" # preserves whitespace

line = "The mill's closed"
f"{line = }"

f"{line = :20}"

f"{line = !r:20}"
```

## Numeric Literals

* integer
* float
* imaginary
